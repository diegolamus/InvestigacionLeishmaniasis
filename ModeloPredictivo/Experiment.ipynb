{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación modelo predictivo\n",
    "\n",
    "## Imports\n",
    "\n",
    "Primero, se importan las dependencias necesarias para la experimentación. Principalmente se trabajará con tensorflow, para calcular metricas, y keras para construir redes neuronales, instanciar redes ya existentes, crear generadores de datos, realizar data augmentatión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import regularizers, initializers, Model\n",
    "from keras.applications import Xception, VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, concatenate\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros \n",
    "\n",
    "Luego, se definen los parametros para la carga de imagenes y el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data loading\n",
    "batch_size = 16\n",
    "imgage_size = 224\n",
    "train_directory = 'src/data/training'\n",
    "test_directory = 'src/data/test'\n",
    "train_images = 1618\n",
    "test_images = 404\n",
    "class_mode = 'binary'\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "save_as= 'Experiment_Xception_transfer' # Name of the files where weigths and history will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de metricas\n",
    "\n",
    "Para la experimentación se utlizará metricas de precision, recall, specificity y kappa. Estas metricas se definen a continuación para, posteriormente, agregarlas al entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric for measuring precision\n",
    "def precision(y_true, y_pred):\n",
    "    return tf.metrics.precision(y_true,y_pred)\n",
    "    #TP,FP = 0,0\n",
    "    #print(len(y_pred))\n",
    "    #if (y_pred == 'positive' and y_true==y_pred):\n",
    "    #    TP +=1\n",
    "    #elif (y_pred == 'positive' and y_true!=y_pred):\n",
    "    #    FP +=1\n",
    "    #return TP / (TP+FP)\n",
    "        \n",
    "# Custom metric for measuring recall    \n",
    "def recall(y_true, y_pred):\n",
    "    TP,FN = 0,0\n",
    "    if (y_pred == 'positive' and y_true==y_pred):\n",
    "        TP +=1\n",
    "    elif (y_pred == 'negative' and y_true!=y_pred):\n",
    "        FN +=1\n",
    "    return TP / (TP+FN)\n",
    "\n",
    "# Custom metric for measuring specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    FP,TN = 0,0\n",
    "    if (y_pred == 'positive' and y_true!=y_pred):\n",
    "        FP +=1\n",
    "    elif (y_pred == 'negative' and y_true==y_pred):\n",
    "        TN +=1\n",
    "    return TP / (TP+FP)\n",
    "\n",
    "# Custom metric for measuring kappa\n",
    "def kappa(y_true, y_pred):\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    if (y_pred == 'positive' and y_true==y_pred):\n",
    "        TP +=1\n",
    "    elif (y_pred == 'positive' and y_true!=y_pred):\n",
    "        FP +=1\n",
    "    elif (y_pred == 'negative' and y_true==y_pred):\n",
    "        TN +=1\n",
    "    elif (y_pred == 'negative' and y_true!=y_pred):\n",
    "        FN +=1\n",
    "    TOTAL = (TP+TN+FP+FN)\n",
    "    OA = (TP+TN)/TOTAL\n",
    "    AC = ((TP+FP)/TOTAL)*((TP+FN)/TOTAL)+((FN+TN)/TOTAL)*((FP+TN)/TOTAL)\n",
    "    return  (OA-AC)/(1-AC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de función de entrenamiento\n",
    "\n",
    "A continuación se define la función con la que se entrenarán los diferentes modelos. Se compila con las metricas definidad anteriormente; se realiza data augmentatión y se entrena el modelo. La función para entrenar recibe el modelo que debe entrenar y retorna la historia del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    # Data generator to transform and rescale training images\n",
    "    # Output: 4 posible transforms over original image\n",
    "    #         (original, horizontal rotation, vertical rotation, horizontal + vertical)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "    # Data generator to rescale test images\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    # Data flow training images\n",
    "    train_flow = train_datagen.flow_from_directory(\n",
    "        directory=train_directory,  \n",
    "        target_size=(imgage_size, imgage_size),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode)\n",
    "    # Data flow test images\n",
    "    test_flow = test_datagen.flow_from_directory(\n",
    "        directory=test_directory,\n",
    "        target_size=(imgage_size, imgage_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode)\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['acc'])#precision,recall,specificity,kappa])\n",
    "    # Create check point call back to store best validation weigths\n",
    "    bestWeigthsPath='src/trainingWeigths/best_' + save_as+'.hdf5'\n",
    "    checkpoint = ModelCheckpoint(bestWeigthsPath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    # Run experiment\n",
    "    history = model.fit_generator(\n",
    "        generator=train_flow,\n",
    "        steps_per_epoch=train_images//batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_flow,\n",
    "        validation_steps=test_images//batch_size,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar modelo\n",
    "\n",
    "Para la posterior integración del modelo con una herramienta movil se exportará el modelo en formato .hdf5. Anteriormente, creamos un checkpoint que cumple con esta función; sin embargo, solo se exportan los pesos del modelo y no el modelo como tal. Teniendo en cuenta lo anterior es necesario cargar los pesos de los mejores resultados de entrenamiento (CheckPoint), y luego exportar el modelo entero (modelo + pesos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(model):\n",
    "    # Load checkpoint weigths\n",
    "    model.load_weights('src/trainingWeigths/bestWeigths' + guardar_como+ '.hdf5')\n",
    "    # Remove file\n",
    "    os.remove('src/trainingWeigths/bestWeigths' + guardar_como+ '.hdf5')\n",
    "    # Create new file saving model and weigths\n",
    "    model.save('src/trainingWeigths/bestWeigths' + guardar_como+ '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cración de modelo predictivo\n",
    "\n",
    "Luego se define una red convolucional y se procede a entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom model\n",
    "def build_CNN_model():\n",
    "    #Input\n",
    "    inputs = Input(shape=(imgage_size,imgage_size,3,))\n",
    "    #BranchOne\n",
    "    branchOne = Conv2D(filters=16,kernel_size=(3,3),activation='relu',\n",
    "                        kernel_initializer=initializers.RandomNormal(stddev=0.1))(inputs)\n",
    "    branchOne = MaxPooling2D(pool_size=(2,2))(branchOne)\n",
    "    branchOne = Conv2D(filters=32,kernel_size=(3,3),activation='relu', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchOne)\n",
    "    branchOne = MaxPooling2D(pool_size=(2,2))(branchOne)    \n",
    "    branchOne = Conv2D(filters=64,kernel_size=(3,3),activation='relu', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchOne)\n",
    "    branchOne = Flatten()(branchOne)\n",
    "    #BranchTwo\n",
    "    branchTwo = Conv2D(filters=16,kernel_size=(5,5),activation='relu',\n",
    "                        kernel_initializer=initializers.RandomNormal(stddev=0.1))(inputs)\n",
    "    branchTwo = MaxPooling2D(pool_size=(2,2))(branchTwo)    \n",
    "    branchTwo = Conv2D(filters=32,kernel_size=(5,5),activation='relu',\n",
    "                        kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchTwo)\n",
    "    branchTwo = MaxPooling2D(pool_size=(2,2))(branchTwo) \n",
    "    branchTwo = Conv2D(filters=64,kernel_size=(5,5),activation='relu',\n",
    "                        kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchTwo)\n",
    "    branchTwo = Flatten()(branchTwo)\n",
    "    #BranchThree\n",
    "    branchThree = Conv2D(filters=16,kernel_size=(3,3),activation='relu',\n",
    "                          kernel_initializer=initializers.RandomNormal(stddev=0.1))(inputs)\n",
    "    branchThree = MaxPooling2D(pool_size=(2,2))(branchThree)     \n",
    "    branchThree = Conv2D(filters=32,kernel_size=(5,5),activation='relu',\n",
    "                             kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchThree)\n",
    "    branchThree = MaxPooling2D(pool_size=(2,2))(branchThree) \n",
    "    branchThree = Conv2D(filters=64,kernel_size=(7,7),activation='relu',\n",
    "                             kernel_initializer=initializers.RandomNormal(stddev=0.1))(branchThree)\n",
    "    branchThree = Flatten()(branchThree)\n",
    "    #Concatenate branches\n",
    "    concatenated = concatenate([branchOne,branchTwo,branchThree], axis=1)\n",
    "    #Clasification layers\n",
    "    clasification = Dropout(0.3)(concatenated)\n",
    "    clasification = Dense(124,activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                           kernel_initializer=initializers.RandomNormal(stddev=0.01))(clasification)\n",
    "    clasification = Dropout(0.3)(clasification)\n",
    "    #Output\n",
    "    out = Dense(1, activation='sigmoid')(clasification)\n",
    "    # Compile Model\n",
    "    model = Model(inputs=[inputs], outputs=[out])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_CNN_model()\n",
    "history = train_model(model)\n",
    "export(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds model for transfer learning and fine tunning\n",
    "def build_transfer_learning_model(conv_layers):\n",
    "    # Freeze conv layers that are not going to be trained\n",
    "    for layer in conv_layers.layers[:]:\n",
    "        layer.trainable = False \n",
    "    # Print summary of the layers\n",
    "    for layer in conv_layers.layers:\n",
    "        print(layer, layer.trainable)    \n",
    "    # Create sequential model\n",
    "    model = Sequential()\n",
    "    # add conv layers to model\n",
    "    model.add(conv_layers)\n",
    "    # Add clasification layers to model\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception\n",
    "\n",
    "La primera red neuronal con la cual se experimentará será Xception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos Xception\n",
    "conv_layers = Xception(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "# Construimos modelo para transfer learning\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = VGG16(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = VGG19(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icesi/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "53182464/94653016 [===============>..............] - ETA: 2:43"
     ]
    }
   ],
   "source": [
    "conv_layers = ResNet50(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = InceptionV3(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = MobileNet(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = DenseNet121(weights='imagenet',include_top=False,input_shape=(imgage_size, imgage_size, 3))\n",
    "model = build_transfer_learning_model(conv_layers)\n",
    "history = train_model(model)\n",
    "export(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
